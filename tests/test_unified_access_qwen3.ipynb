{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Adjust path to include src if running from a subdirectory like 'notebooks'\n",
    "sys.path.append(os.path.abspath(\"../src\"))\n",
    "\n",
    "from mech_interp_toolkit.utils import load_model_tokenizer_config\n",
    "from mech_interp_toolkit.activations import UnifiedAccessAndPatching\n",
    "from mech_interp_toolkit.activation_dict import ActivationDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Qwen/Qwen3-0.6B\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(f\"Loading model {model_name} on {device}...\")\n",
    "model, tokenizer, config = load_model_tokenizer_config(model_name, device=device)\n",
    "print(\"Model loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\n",
    "    \"The capital of France is Paris.\",\n",
    "    \"The capital of Germany is Berlin.\"\n",
    "]\n",
    "inputs = tokenizer(prompts, thinking=False)\n",
    "print(\"Input keys:\", inputs.keys())\n",
    "print(\"Input shape:\", inputs[\"input_ids\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_layers = config.num_hidden_layers\n",
    "print(f\"Number of layers: {n_layers}\")\n",
    "\n",
    "spec_dict = {\n",
    "    \"activations\": {\n",
    "        \"positions\": -1,\n",
    "        \"locations\": [(n_layers - 1, \"layer_out\")],\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Running UnifiedAccessAndPatching (Clean)...\")\n",
    "with UnifiedAccessAndPatching(model, inputs, spec_dict) as uap:\n",
    "    activations, logits = uap.unified_access_and_patching()\n",
    "\n",
    "print(\"Logits shape:\", logits.shape)\n",
    "act_shape = activations[(n_layers - 1, \"layer_out\")].shape\n",
    "print(f\"Activation at layer {n_layers - 1} (layer_out) shape: {act_shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Patching: Zero out 'z' at layer 5\n",
    "layer_to_patch = 5\n",
    "component_to_patch = \"z\"\n",
    "\n",
    "batch_size = inputs[\"input_ids\"].shape[0]\n",
    "seq_len = inputs[\"input_ids\"].shape[1]\n",
    "hidden_size = config.hidden_size\n",
    "\n",
    "patch_data = ActivationDict(config, positions=slice(None))\n",
    "patch_tensor = torch.zeros((batch_size, seq_len, hidden_size), device=device, dtype=model.dtype)\n",
    "patch_data[(layer_to_patch, component_to_patch)] = patch_tensor\n",
    "\n",
    "patch_spec = {\n",
    "    \"patching\": patch_data,\n",
    "    \"activations\": {\n",
    "        \"positions\": -1,\n",
    "        \"locations\": [(n_layers - 1, \"layer_out\")],\n",
    "    }\n",
    "}\n",
    "\n",
    "print(f\"Running UnifiedAccessAndPatching with patching at layer {layer_to_patch}...\")\n",
    "with UnifiedAccessAndPatching(model, inputs, patch_spec) as uap:\n",
    "    patched_activations, patched_logits = uap.unified_access_and_patching()\n",
    "\n",
    "print(\"Patched Logits shape:\", patched_logits.shape)\n",
    "diff = (logits - patched_logits).abs().sum()\n",
    "print(f\"Difference in logits (Clean vs Patched): {diff.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Gradients\n",
    "spec_dict_grad = {\n",
    "    \"activations\": {\n",
    "        \"positions\": -1,\n",
    "        \"locations\": [(0, \"layer_in\")],\n",
    "        \"gradients\": {\n",
    "            \"metric_fn\": lambda x: x.max(dim=-1).values.sum(),\n",
    "            \"compute_metric_at\": (-1, \"logits\")\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Running UnifiedAccessAndPatching (Gradients)...\")\n",
    "with UnifiedAccessAndPatching(model, inputs, spec_dict_grad) as uap:\n",
    "    grads_output, _ = uap.unified_access_and_patching()\n",
    "\n",
    "grad_tensor = grads_output[(0, \"layer_in\")].grad\n",
    "if grad_tensor is not None:\n",
    "    print(\"Gradient shape:\", grad_tensor.shape)\n",
    "    print(\"Gradient norm:\", grad_tensor.norm().item())\n",
    "else:\n",
    "    print(\"Gradient not found.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}