{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# !git clone https://github.com/SD-interp/mech_interp_toolkit.git\n",
        "# %cd mech_interp_toolkit\n",
        "# !pip install -e ."
      ],
      "metadata": {
        "id": "ihqJlf2bZ1Zf"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kohycrbbZh7S"
      },
      "source": [
        "# Test: activation_dict module\n",
        "\n",
        "This notebook tests `FrozenError`, `FreezableDict`, `ArithmeticOperation`, and `ActivationDict` classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bjjk3nipZh7W"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "sys.path.append(os.path.abspath(\"../src\"))\n",
        "\n",
        "import torch\n",
        "from transformers import AutoConfig\n",
        "from mech_interp_toolkit.activation_dict import (\n",
        "    FrozenError,\n",
        "    FreezableDict,\n",
        "    ArithmeticOperation,\n",
        "    ActivationDict,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opJ4BR-4Zh7Y"
      },
      "source": [
        "## Setup: Load model config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "EnZSk40SZh7Y",
        "outputId": "0a2cfac0-80ef-4690-a0ca-ae4bd03fba10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213,
          "referenced_widgets": [
            "e0e211551f3c4d3b9e93f07071c14868",
            "3aea0c82f24d4d489b14363a283b5834",
            "2bfcba881541490692af81d7e4ea95e4",
            "3f4c85aacfd24826bf64164b6baa0bac",
            "05f15352fa9041b0abea282faf3a1ed4",
            "a340b130eb9e406c9f9da38e4829d990",
            "b736dc13c380418585d5ff8ede3217ae",
            "284aed7f8e8b4f69816e9785b7ca597d",
            "82849349dc2e4e07a230764403037bcd",
            "78213092afe64d39bfee77f7eaaa1f55",
            "9b8022afedf2454aa25cd3bcad70d50d"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:104: UserWarning: \n",
            "Error while fetching `HF_TOKEN` secret value from your vault: 'Requesting secret HF_TOKEN timed out. Secrets can only be fetched when running from the Colab UI.'.\n",
            "You are not authenticated with the Hugging Face Hub in this notebook.\n",
            "If the error persists, please let us know by opening an issue on GitHub (https://github.com/huggingface/huggingface_hub/issues/new).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/726 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e0e211551f3c4d3b9e93f07071c14868"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded config for Qwen/Qwen3-0.6B\n",
            "Hidden size: 1024\n",
            "Num attention heads: 16\n",
            "Num hidden layers: 28\n"
          ]
        }
      ],
      "source": [
        "model_name = \"Qwen/Qwen3-0.6B\"\n",
        "config = AutoConfig.from_pretrained(model_name)\n",
        "print(f\"Loaded config for {model_name}\")\n",
        "print(f\"Hidden size: {config.hidden_size}\")\n",
        "print(f\"Num attention heads: {config.num_attention_heads}\")\n",
        "print(f\"Num hidden layers: {config.num_hidden_layers}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_T5FmEJuZh7Y"
      },
      "source": [
        "## Test: FrozenError exception"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "-WSWZL3eZh7Z",
        "outputId": "1c8bfbe6-b81c-4ce9-c127-a5956dcbe429",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Caught FrozenError: Test error message\n",
            "PASSED: FrozenError exception\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    raise FrozenError(\"Test error message\")\n",
        "except FrozenError as e:\n",
        "    print(f\"Caught FrozenError: {e}\")\n",
        "    assert \"Test error message\" in str(e)\n",
        "print(\"PASSED: FrozenError exception\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q__v1KLnZh7a"
      },
      "source": [
        "## Test: ActivationDict initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "WS9GLbQkZh7a",
        "outputId": "8a81b5c3-2f0c-46d8-a271-7e16f141b1a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_heads: 16\n",
            "num_layers: 28\n",
            "head_dim: 64\n",
            "model_dim: 1024\n",
            "fused_heads: True\n",
            "value_type: activation\n",
            "PASSED: ActivationDict initialization\n"
          ]
        }
      ],
      "source": [
        "# Test basic initialization\n",
        "act_dict = ActivationDict(config, positions=slice(None))\n",
        "\n",
        "print(f\"num_heads: {act_dict.num_heads}\")\n",
        "print(f\"num_layers: {act_dict.num_layers}\")\n",
        "print(f\"head_dim: {act_dict.head_dim}\")\n",
        "print(f\"model_dim: {act_dict.model_dim}\")\n",
        "print(f\"fused_heads: {act_dict.fused_heads}\")\n",
        "print(f\"value_type: {act_dict.value_type}\")\n",
        "\n",
        "assert act_dict.num_heads == config.num_attention_heads\n",
        "assert act_dict.num_layers == config.num_hidden_layers\n",
        "assert act_dict.head_dim == config.hidden_size // config.num_attention_heads\n",
        "assert act_dict.model_dim == config.hidden_size\n",
        "assert act_dict.fused_heads == True\n",
        "assert act_dict.value_type == \"activation\"\n",
        "print(\"PASSED: ActivationDict initialization\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "3wDpKYOzZh7a",
        "outputId": "908bb9d6-d97d-44d6-9a3a-5faa76cc1ffe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PASSED: Different value_type initialization\n"
          ]
        }
      ],
      "source": [
        "# Test initialization with different value_type\n",
        "grad_dict = ActivationDict(config, positions=-1, value_type=\"gradient\")\n",
        "assert grad_dict.value_type == \"gradient\"\n",
        "\n",
        "score_dict = ActivationDict(config, positions=[0, 1, 2], value_type=\"scores\")\n",
        "assert score_dict.value_type == \"scores\"\n",
        "print(\"PASSED: Different value_type initialization\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8aRT5ydZh7b"
      },
      "source": [
        "## Test: Freeze/Unfreeze functionality"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ogCQl5D5Zh7b",
        "outputId": "ad0e4af8-c69f-4aa8-9a45-1633706ed31e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Added (0, 'attn'): torch.Size([2, 10, 1024])\n",
            "Dictionary frozen\n",
            "Correctly raised FrozenError on setitem\n",
            "Correctly raised FrozenError on delitem\n",
            "Correctly raised FrozenError on clear\n",
            "After unfreeze, added (0, 'mlp'): torch.Size([2, 10, 1024])\n",
            "PASSED: Freeze/Unfreeze functionality\n"
          ]
        }
      ],
      "source": [
        "act_dict = ActivationDict(config, positions=slice(None))\n",
        "\n",
        "# Add data before freezing\n",
        "act_dict[(0, \"attn\")] = torch.randn(2, 10, config.hidden_size)\n",
        "print(f\"Added (0, 'attn'): {act_dict[(0, 'attn')].shape}\")\n",
        "\n",
        "# Freeze the dictionary\n",
        "act_dict.freeze()\n",
        "assert act_dict._frozen == True, \"Should be frozen\"\n",
        "print(\"Dictionary frozen\")\n",
        "\n",
        "# Try to modify while frozen (should raise FrozenError)\n",
        "try:\n",
        "    act_dict[(0, \"mlp\")] = torch.randn(2, 10, config.hidden_size)\n",
        "    assert False, \"Should have raised FrozenError\"\n",
        "except FrozenError:\n",
        "    print(\"Correctly raised FrozenError on setitem\")\n",
        "\n",
        "# Try other modifying operations\n",
        "try:\n",
        "    del act_dict[(0, \"attn\")]\n",
        "    assert False, \"Should have raised FrozenError\"\n",
        "except FrozenError:\n",
        "    print(\"Correctly raised FrozenError on delitem\")\n",
        "\n",
        "try:\n",
        "    act_dict.clear()\n",
        "    assert False, \"Should have raised FrozenError\"\n",
        "except FrozenError:\n",
        "    print(\"Correctly raised FrozenError on clear\")\n",
        "\n",
        "# Unfreeze and modify\n",
        "act_dict.unfreeze()\n",
        "assert act_dict._frozen == False, \"Should be unfrozen\"\n",
        "act_dict[(0, \"mlp\")] = torch.randn(2, 10, config.hidden_size)\n",
        "print(f\"After unfreeze, added (0, 'mlp'): {act_dict[(0, 'mlp')].shape}\")\n",
        "print(\"PASSED: Freeze/Unfreeze functionality\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKJ-hK_wZh7b"
      },
      "source": [
        "## Test: clone()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ow4N_i7zZh7b",
        "outputId": "4adb5d0e-a066-408a-aca2-d56fa3b590aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original sum: 75.58676147460938\n",
            "Cloned sum (after zeroing): 0.0\n",
            "PASSED: clone()\n"
          ]
        }
      ],
      "source": [
        "original = ActivationDict(config, positions=slice(None))\n",
        "original[(0, \"attn\")] = torch.randn(2, 5, config.hidden_size)\n",
        "\n",
        "cloned = original.clone()\n",
        "\n",
        "# Verify clone has same data\n",
        "assert (0, \"attn\") in cloned, \"Cloned should have same keys\"\n",
        "assert torch.equal(original[(0, \"attn\")], cloned[(0, \"attn\")]), \"Data should be equal\"\n",
        "\n",
        "# Verify clone is independent (deep copy)\n",
        "cloned[(0, \"attn\")] = torch.zeros_like(cloned[(0, \"attn\")])\n",
        "assert not torch.equal(original[(0, \"attn\")], cloned[(0, \"attn\")]), \"Modifying clone should not affect original\"\n",
        "\n",
        "print(\"Original sum:\", original[(0, \"attn\")].sum().item())\n",
        "print(\"Cloned sum (after zeroing):\", cloned[(0, \"attn\")].sum().item())\n",
        "print(\"PASSED: clone()\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWB0xaoOZh7b"
      },
      "source": [
        "## Test: Arithmetic operations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "RjnCUhiVZh7c"
      },
      "outputs": [],
      "source": [
        "# Create two ActivationDicts with same keys\n",
        "act1 = ActivationDict(config, positions=slice(None))\n",
        "act1[(0, \"attn\")] = torch.ones(2, 5, config.hidden_size) * 3\n",
        "act1[(0, \"mlp\")] = torch.ones(2, 5, config.hidden_size) * 5\n",
        "\n",
        "act2 = ActivationDict(config, positions=slice(None))\n",
        "act2[(0, \"attn\")] = torch.ones(2, 5, config.hidden_size) * 2\n",
        "act2[(0, \"mlp\")] = torch.ones(2, 5, config.hidden_size) * 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "A4gerVdDZh7c",
        "outputId": "9fe2ae08-d115-4cff-e9e2-0fffe1ef6efb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Addition: 3 + 2 = 5.0\n",
            "PASSED: Addition\n"
          ]
        }
      ],
      "source": [
        "# Test addition\n",
        "result = act1 + act2\n",
        "assert torch.allclose(result[(0, \"attn\")], torch.ones(2, 5, config.hidden_size) * 5)\n",
        "assert torch.allclose(result[(0, \"mlp\")], torch.ones(2, 5, config.hidden_size) * 8)\n",
        "print(f\"Addition: 3 + 2 = {result[(0, 'attn')][0, 0, 0].item()}\")\n",
        "print(\"PASSED: Addition\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "w4gKNVrQZh7c",
        "outputId": "38f890dc-b0b7-4f2a-97cc-7b67da550eb8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Subtraction: 3 - 2 = 1.0\n",
            "PASSED: Subtraction\n"
          ]
        }
      ],
      "source": [
        "# Test subtraction\n",
        "result = act1 - act2\n",
        "assert torch.allclose(result[(0, \"attn\")], torch.ones(2, 5, config.hidden_size) * 1)\n",
        "assert torch.allclose(result[(0, \"mlp\")], torch.ones(2, 5, config.hidden_size) * 2)\n",
        "print(f\"Subtraction: 3 - 2 = {result[(0, 'attn')][0, 0, 0].item()}\")\n",
        "print(\"PASSED: Subtraction\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "AC5bRx0tZh7c",
        "outputId": "63b5365b-fb8d-4013-a330-ab98708ae327",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Multiplication (ActivationDict): 3 * 2 = 6.0\n",
            "PASSED: Multiplication (ActivationDict)\n"
          ]
        }
      ],
      "source": [
        "# Test multiplication with ActivationDict\n",
        "result = act1 * act2\n",
        "assert torch.allclose(result[(0, \"attn\")], torch.ones(2, 5, config.hidden_size) * 6)\n",
        "assert torch.allclose(result[(0, \"mlp\")], torch.ones(2, 5, config.hidden_size) * 15)\n",
        "print(f\"Multiplication (ActivationDict): 3 * 2 = {result[(0, 'attn')][0, 0, 0].item()}\")\n",
        "print(\"PASSED: Multiplication (ActivationDict)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "SHqJI98FZh7d",
        "outputId": "d6f53817-e48c-4fd4-dfcc-3cf73d328ca5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Multiplication (scalar): 3 * 2.0 = 6.0\n",
            "Reverse multiplication: 2.0 * 3 = 6.0\n",
            "PASSED: Scalar multiplication\n"
          ]
        }
      ],
      "source": [
        "# Test multiplication with scalar\n",
        "result = act1 * 2.0\n",
        "assert torch.allclose(result[(0, \"attn\")], torch.ones(2, 5, config.hidden_size) * 6)\n",
        "print(f\"Multiplication (scalar): 3 * 2.0 = {result[(0, 'attn')][0, 0, 0].item()}\")\n",
        "\n",
        "# Test rmul\n",
        "result = 2.0 * act1\n",
        "assert torch.allclose(result[(0, \"attn\")], torch.ones(2, 5, config.hidden_size) * 6)\n",
        "print(f\"Reverse multiplication: 2.0 * 3 = {result[(0, 'attn')][0, 0, 0].item()}\")\n",
        "print(\"PASSED: Scalar multiplication\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "j8wP2JLdZh7d",
        "outputId": "e4b7ff76-c83f-4ad0-d06e-1af92bca1bdd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Division (ActivationDict): 3 / 2 = 1.5\n",
            "Division (scalar): 3 / 2.0 = 1.5\n",
            "PASSED: Division\n"
          ]
        }
      ],
      "source": [
        "# Test division\n",
        "result = act1 / act2\n",
        "assert torch.allclose(result[(0, \"attn\")], torch.ones(2, 5, config.hidden_size) * 1.5)\n",
        "print(f\"Division (ActivationDict): 3 / 2 = {result[(0, 'attn')][0, 0, 0].item()}\")\n",
        "\n",
        "result = act1 / 2.0\n",
        "assert torch.allclose(result[(0, \"attn\")], torch.ones(2, 5, config.hidden_size) * 1.5)\n",
        "print(f\"Division (scalar): 3 / 2.0 = {result[(0, 'attn')][0, 0, 0].item()}\")\n",
        "print(\"PASSED: Division\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PcH310AIZh7d"
      },
      "source": [
        "## Test: split_heads() and merge_heads()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "k4i_oq3JZh7e",
        "outputId": "e01c576a-36af-4caa-de05-ec074d3bca03",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original z shape (fused): torch.Size([2, 10, 1024])\n",
            "After split_heads z shape: torch.Size([2, 10, 16, 64])\n",
            "PASSED: split_heads()\n"
          ]
        }
      ],
      "source": [
        "act_dict = ActivationDict(config, positions=slice(None))\n",
        "batch_size, seq_len = 2, 10\n",
        "# z activations with fused heads: (batch, pos, n_heads * d_head)\n",
        "act_dict[(0, \"z\")] = torch.randn(batch_size, seq_len, config.hidden_size)\n",
        "print(f\"Original z shape (fused): {act_dict[(0, 'z')].shape}\")\n",
        "assert act_dict.fused_heads == True\n",
        "\n",
        "# Split heads\n",
        "act_dict.split_heads()\n",
        "print(f\"After split_heads z shape: {act_dict[(0, 'z')].shape}\")\n",
        "expected_shape = (batch_size, seq_len, act_dict.num_heads, act_dict.head_dim)\n",
        "assert act_dict[(0, \"z\")].shape == expected_shape, f\"Expected {expected_shape}, got {act_dict[(0, 'z')].shape}\"\n",
        "assert act_dict.fused_heads == False\n",
        "print(\"PASSED: split_heads()\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "8NdGB_CDZh7e",
        "outputId": "78c718b8-7414-4b3a-9854-fc401ef61329",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After merge_heads z shape: torch.Size([2, 10, 1024])\n",
            "PASSED: merge_heads()\n"
          ]
        }
      ],
      "source": [
        "# Merge heads back\n",
        "act_dict.merge_heads()\n",
        "print(f\"After merge_heads z shape: {act_dict[(0, 'z')].shape}\")\n",
        "expected_shape = (batch_size, seq_len, config.hidden_size)\n",
        "assert act_dict[(0, \"z\")].shape == expected_shape, f\"Expected {expected_shape}, got {act_dict[(0, 'z')].shape}\"\n",
        "assert act_dict.fused_heads == True\n",
        "print(\"PASSED: merge_heads()\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltUP1mUwZh7e"
      },
      "source": [
        "## Test: apply()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "A65QQD1_Zh7e",
        "outputId": "5046e2f7-070c-45b6-8378-653925b5cc2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original shape: torch.Size([2, 5, 1024])\n",
            "After apply(sum, dim=-1) shape: torch.Size([2, 5])\n",
            "Sum value: 3072.0 (expected 3072)\n",
            "PASSED: apply()\n"
          ]
        }
      ],
      "source": [
        "act_dict = ActivationDict(config, positions=slice(None))\n",
        "act_dict[(0, \"attn\")] = torch.ones(2, 5, config.hidden_size) * 3\n",
        "act_dict[(0, \"mlp\")] = torch.ones(2, 5, config.hidden_size) * 5\n",
        "\n",
        "# Apply sum along last dimension\n",
        "summed = act_dict.apply(torch.sum, dim=-1)\n",
        "print(f\"Original shape: {act_dict[(0, 'attn')].shape}\")\n",
        "print(f\"After apply(sum, dim=-1) shape: {summed[(0, 'attn')].shape}\")\n",
        "\n",
        "expected_sum = 3 * config.hidden_size\n",
        "assert torch.allclose(summed[(0, \"attn\")], torch.ones(2, 5) * expected_sum)\n",
        "print(f\"Sum value: {summed[(0, 'attn')][0, 0].item()} (expected {expected_sum})\")\n",
        "print(\"PASSED: apply()\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PptM8Gt4Zh7e"
      },
      "source": [
        "## Test: cuda() and cpu()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "IgH9ZCBDZh7e",
        "outputId": "090bccb6-c70f-4b6d-c61d-1db368e70acc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device after cpu(): cpu\n",
            "Device after cuda(): cuda:0\n",
            "PASSED: cuda() and cpu()\n"
          ]
        }
      ],
      "source": [
        "act_dict = ActivationDict(config, positions=slice(None))\n",
        "act_dict[(0, \"attn\")] = torch.randn(2, 5, config.hidden_size)\n",
        "\n",
        "# Test cpu()\n",
        "act_dict.cpu()\n",
        "assert act_dict[(0, \"attn\")].device.type == \"cpu\", \"Should be on CPU\"\n",
        "print(f\"Device after cpu(): {act_dict[(0, 'attn')].device}\")\n",
        "\n",
        "# Test cuda() if available\n",
        "if torch.cuda.is_available():\n",
        "    act_dict.cuda()\n",
        "    assert act_dict[(0, \"attn\")].device.type == \"cuda\", \"Should be on CUDA\"\n",
        "    print(f\"Device after cuda(): {act_dict[(0, 'attn')].device}\")\n",
        "    act_dict.cpu()  # Move back to CPU\n",
        "else:\n",
        "    print(\"CUDA not available, skipping cuda() test\")\n",
        "\n",
        "print(\"PASSED: cuda() and cpu()\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ty3ULoAZh7f"
      },
      "source": [
        "## Test: zeros_like()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "AAhkznkHZh7f",
        "outputId": "adaccc08-5c98-4b6c-dc60-710c0c9094bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "zeros_like() sum: 0.0\n",
            "PASSED: zeros_like()\n"
          ]
        }
      ],
      "source": [
        "act_dict = ActivationDict(config, positions=slice(None))\n",
        "act_dict[(0, \"attn\")] = torch.randn(2, 5, config.hidden_size)\n",
        "act_dict[(0, \"mlp\")] = torch.randn(2, 5, config.hidden_size)\n",
        "\n",
        "# Create zeros for all keys\n",
        "zeros = act_dict.zeros_like()\n",
        "assert torch.all(zeros[(0, \"attn\")] == 0), \"Should be all zeros\"\n",
        "assert zeros[(0, \"attn\")].shape == act_dict[(0, \"attn\")].shape, \"Shape should match\"\n",
        "print(f\"zeros_like() sum: {zeros[(0, 'attn')].sum().item()}\")\n",
        "\n",
        "# Create zeros for specific keys\n",
        "zeros_partial = act_dict.zeros_like(keys=[(0, \"attn\")])\n",
        "assert (0, \"attn\") in zeros_partial, \"Should have requested key\"\n",
        "assert (0, \"mlp\") not in zeros_partial, \"Should not have unrequested key\"\n",
        "print(\"PASSED: zeros_like()\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vvjdrLiZh7f"
      },
      "source": [
        "## Test: reorganize()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "aZZmQikVZh7f",
        "outputId": "27dc2d82-923e-477c-ebc3-eaef234988d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original order: [(1, 'mlp'), (0, 'z'), (0, 'layer_in'), (0, 'mlp'), (0, 'attn')]\n",
            "Reorganized order: [(0, 'layer_in'), (0, 'z'), (0, 'attn'), (0, 'mlp'), (1, 'mlp')]\n",
            "PASSED: reorganize()\n"
          ]
        }
      ],
      "source": [
        "act_dict = ActivationDict(config, positions=slice(None))\n",
        "# Add in random order\n",
        "act_dict[(1, \"mlp\")] = torch.randn(2, 5, config.hidden_size)\n",
        "act_dict[(0, \"z\")] = torch.randn(2, 5, config.hidden_size)\n",
        "act_dict[(0, \"layer_in\")] = torch.randn(2, 5, config.hidden_size)\n",
        "act_dict[(0, \"mlp\")] = torch.randn(2, 5, config.hidden_size)\n",
        "act_dict[(0, \"attn\")] = torch.randn(2, 5, config.hidden_size)\n",
        "\n",
        "print(f\"Original order: {list(act_dict.keys())}\")\n",
        "\n",
        "reorganized = act_dict.reorganize()\n",
        "print(f\"Reorganized order: {list(reorganized.keys())}\")\n",
        "\n",
        "# Expected order: (0, layer_in), (0, z), (0, attn), (0, mlp), (1, mlp)\n",
        "keys = list(reorganized.keys())\n",
        "assert keys[0] == (0, \"layer_in\"), \"First should be (0, 'layer_in')\"\n",
        "assert keys[1] == (0, \"z\"), \"Second should be (0, 'z')\"\n",
        "assert keys[2] == (0, \"attn\"), \"Third should be (0, 'attn')\"\n",
        "assert keys[3] == (0, \"mlp\"), \"Fourth should be (0, 'mlp')\"\n",
        "assert keys[4] == (1, \"mlp\"), \"Fifth should be (1, 'mlp')\"\n",
        "print(\"PASSED: reorganize()\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BetaVCx-Zh7g"
      },
      "source": [
        "## Test: extract_positions()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "eVo7xk2IZh7h",
        "outputId": "6ae11d5d-07ef-4b74-8c47-b603768ca68b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original shape: torch.Size([2, 10, 1024])\n",
            "Extracted shape: torch.Size([2, 2, 1024])\n",
            "PASSED: extract_positions()\n"
          ]
        }
      ],
      "source": [
        "act_dict = ActivationDict(config, positions=[1, 3])  # positions to extract\n",
        "act_dict[(0, \"attn\")] = torch.randn(2, 10, config.hidden_size)  # Full sequence\n",
        "\n",
        "extracted = act_dict.extract_positions()\n",
        "print(f\"Original shape: {act_dict[(0, 'attn')].shape}\")\n",
        "print(f\"Extracted shape: {extracted[(0, 'attn')].shape}\")\n",
        "\n",
        "# Should extract positions [1, 3] -> shape (batch, 2, hidden_size)\n",
        "assert extracted[(0, \"attn\")].shape == (2, 2, config.hidden_size)\n",
        "print(\"PASSED: extract_positions()\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44p67_1XZh7i"
      },
      "source": [
        "## Test: get_grads()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "hI7lMiVBZh7i",
        "outputId": "25a46379-113c-46dc-8d1f-97cf620f97ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient exists: True\n",
            "Gradient shape: torch.Size([2, 5, 1024])\n",
            "Retrieved gradient shape: torch.Size([2, 5, 1024])\n",
            "PASSED: get_grads()\n"
          ]
        }
      ],
      "source": [
        "act_dict = ActivationDict(config, positions=slice(None))\n",
        "tensor = torch.randn(2, 5, config.hidden_size, requires_grad=True)\n",
        "act_dict[(0, \"attn\")] = tensor\n",
        "\n",
        "# Compute some gradients\n",
        "loss = tensor.sum()\n",
        "loss.backward()\n",
        "\n",
        "print(f\"Gradient exists: {tensor.grad is not None}\")\n",
        "print(f\"Gradient shape: {tensor.grad.shape}\")\n",
        "\n",
        "# Get gradients\n",
        "grads = act_dict.get_grads()\n",
        "assert grads.value_type == \"gradient\", \"Should have gradient value_type\"\n",
        "assert grads[(0, \"attn\")] is not None, \"Should have gradient\"\n",
        "print(f\"Retrieved gradient shape: {grads[(0, 'attn')].shape}\")\n",
        "print(\"PASSED: get_grads()\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgGGwKkiZh7j"
      },
      "source": [
        "## Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "WgbgTXenZh7j",
        "outputId": "31688877-40fe-48f5-ba10-9f7fbfb407dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================================\n",
            "All activation_dict module tests PASSED!\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "print(\"=\"*50)\n",
        "print(\"All activation_dict module tests PASSED!\")\n",
        "print(\"=\"*50)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.0"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e0e211551f3c4d3b9e93f07071c14868": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3aea0c82f24d4d489b14363a283b5834",
              "IPY_MODEL_2bfcba881541490692af81d7e4ea95e4",
              "IPY_MODEL_3f4c85aacfd24826bf64164b6baa0bac"
            ],
            "layout": "IPY_MODEL_05f15352fa9041b0abea282faf3a1ed4"
          }
        },
        "3aea0c82f24d4d489b14363a283b5834": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a340b130eb9e406c9f9da38e4829d990",
            "placeholder": "​",
            "style": "IPY_MODEL_b736dc13c380418585d5ff8ede3217ae",
            "value": "config.json: 100%"
          }
        },
        "2bfcba881541490692af81d7e4ea95e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_284aed7f8e8b4f69816e9785b7ca597d",
            "max": 726,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_82849349dc2e4e07a230764403037bcd",
            "value": 726
          }
        },
        "3f4c85aacfd24826bf64164b6baa0bac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78213092afe64d39bfee77f7eaaa1f55",
            "placeholder": "​",
            "style": "IPY_MODEL_9b8022afedf2454aa25cd3bcad70d50d",
            "value": " 726/726 [00:00&lt;00:00, 80.1kB/s]"
          }
        },
        "05f15352fa9041b0abea282faf3a1ed4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a340b130eb9e406c9f9da38e4829d990": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b736dc13c380418585d5ff8ede3217ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "284aed7f8e8b4f69816e9785b7ca597d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82849349dc2e4e07a230764403037bcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "78213092afe64d39bfee77f7eaaa1f55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b8022afedf2454aa25cd3bcad70d50d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}